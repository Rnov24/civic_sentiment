{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is for collecting data for the project. You can use the enhanced `scraping.py` module to scrape comments from YouTube videos with improved verbose output showing video titles during the scraping process.\n",
    "\n",
    "## New Features:\n",
    "- **Video Title Display**: Progress bars and logs now show video titles instead of just IDs\n",
    "- **Enhanced Data**: Scraped data includes both video ID and video title columns\n",
    "- **Better Error Handling**: More informative error messages with video context\n",
    "- **Flexible API Key**: Can be provided via parameter or environment variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using Google Colab, run the following cell to set up your environment. If you are working locally, you can skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import toml\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# --- 1. Clone your GitHub repository ---\n",
    "repo_url = \"https://github.com/rnov24/civic_sentiment.git\"\n",
    "repo_name = \"civic_sentiment\"  # Should match the PROJ_ROOT in config.py\n",
    "clone_path = Path(\"/content\") / repo_name\n",
    "\n",
    "if not clone_path.exists():\n",
    "    # For private repositories, you'll need to use a GitHub token\n",
    "    # from getpass import getpass\n",
    "    # token = getpass('Enter your GitHub token: ')\n",
    "    # repo_url = repo_url.replace(\"https://\", f\"https://{token}@\")\n",
    "    subprocess.run([\"git\", \"clone\", repo_url, str(clone_path)], check=True)\n",
    "else:\n",
    "    print(\"Repository already cloned.\")\n",
    "\n",
    "# --- 2. Install project dependencies ---\n",
    "sys.path.append(str(clone_path))\n",
    "pyproject_path = clone_path / \"pyproject.toml\"\n",
    "\n",
    "with open(pyproject_path, \"r\") as f:\n",
    "    pyproject = toml.load(f)\n",
    "\n",
    "dependencies = pyproject[\"project\"][\"dependencies\"]\n",
    "subprocess.run([\"pip\", \"install\"] + dependencies, check=True)\n",
    "\n",
    "# --- 3. Now you can import your project modules ---\n",
    "# The PROJ_ROOT in config.py is now correctly set to /content/civic_sentiment\n",
    "from civic_sentiment.config import RAW_DATA_DIR\n",
    "\n",
    "print(\"\\nEnvironment setup complete!\")\n",
    "print(f\"Raw data directory: {RAW_DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Scrape YouTube Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from civic_sentiment.scraping import scrape_videos\n",
    "import os\n",
    "\n",
    "# Get the API key from the environment variable or set it directly\n",
    "API_KEY = os.getenv(\"YOUTUBE_API_KEY\")\n",
    "\n",
    "\n",
    "# Example: Scrape comments from multiple videos with enhanced verbose output\n",
    "video_ids = [\n",
    "    \"LJ8yd0uRvwY\",\n",
    "    \"oOf1b1P6fGc\",\n",
    "]\n",
    "\n",
    "if API_KEY:\n",
    "    print(f\"Scraping comments from {len(video_ids)} videos...\")\n",
    "    comments_df = scrape_videos(API_KEY, video_ids)\n",
    "    print(f\"\\n‚úÖ Found {len(comments_df)} comments from {comments_df['video_id'].nunique()} videos.\")\n",
    "    \n",
    "    # Display video titles that were scraped\n",
    "    if not comments_df.empty:\n",
    "        print(\"\\nüì∫ Videos processed:\")\n",
    "        for video_id, title in comments_df[['video_id', 'video_title']].drop_duplicates().values:\n",
    "            print(f\"  ‚Ä¢ {video_id}: {title}\")\n",
    "else:\n",
    "    print(\"‚ùå YOUTUBE_API_KEY environment variable not set.\")\n",
    "    print(\"Please set your YouTube Data API key either:\")\n",
    "    print(\"1. As an environment variable: export YOUTUBE_API_KEY=your_key\")\n",
    "    print(\"2. Or modify the API_KEY variable in this cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 5 rows of the DataFrame with the new video_title column\n",
    "if not comments_df.empty:\n",
    "    print(\"üìä Sample of scraped comments:\")\n",
    "    print(f\"Columns: {list(comments_df.columns)}\")\n",
    "    print(f\"Shape: {comments_df.shape}\")\n",
    "    print(\"\\nFirst 5 comments:\")\n",
    "    display(comments_df.head())\n",
    "    \n",
    "    # Show some basic statistics\n",
    "    print(f\"\\nüìà Summary:\")\n",
    "    print(f\"Total comments: {len(comments_df)}\")\n",
    "    print(f\"Unique videos: {comments_df['video_id'].nunique()}\")\n",
    "    print(f\"Unique authors: {comments_df['author'].nunique()}\")\n",
    "    \n",
    "    # Show comments per video\n",
    "    print(f\"\\nüì∫ Comments per video:\")\n",
    "    video_stats = comments_df.groupby(['video_id', 'video_title']).size().reset_index(name='comment_count')\n",
    "    for _, row in video_stats.iterrows():\n",
    "        title_preview = row['video_title'][:50] + \"...\" if len(row['video_title']) > 50 else row['video_title']\n",
    "        print(f\"  {row['video_id']}: {row['comment_count']} comments\")\n",
    "        print(f\"    Title: {title_preview}\")\n",
    "else:\n",
    "    print(\"No comments were scraped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "if not comments_df.empty:\n",
    "    output_path = RAW_DATA_DIR / \"comments.csv\"\n",
    "    comments_df.to_csv(output_path, index=False)\n",
    "    print(f\"üíæ Comments saved to {output_path}\")\n",
    "    print(f\"üìÅ File size: {output_path.stat().st_size / 1024:.1f} KB\")\n",
    "    \n",
    "    # Show a preview of what was saved\n",
    "    print(f\"\\nüìã Data saved includes:\")\n",
    "    print(f\"  ‚Ä¢ {len(comments_df)} total comments\")\n",
    "    print(f\"  ‚Ä¢ {comments_df['video_id'].nunique()} unique videos\")\n",
    "    print(f\"  ‚Ä¢ Columns: {', '.join(comments_df.columns)}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No data to save - comments DataFrame is empty\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
